\documentclass[a4paper]{article}
\usepackage{iwslt14,amssymb,amsmath,epsfig,url}
\setcounter{page}{1}
\sloppy		% better line breaks
%\ninept
%SM below a registered trademark definition
\def\reg{{\rm\ooalign{\hfil
     \raise.07ex\hbox{\scriptsize R}\hfil\crcr\mathhexbox20D}}}

\usepackage{mathptmx}
\usepackage{fp}
\usepackage{xspace}
\usepackage{color}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{booktabs}

\def\roundposition{1}
\def\roundpositiont{3}
\edef\rounded{0}
\newcommand{\rdm}[1]{\edef\rounded{0}\FPeval\rounded{round(#1,\roundposition)}\rounded}
\newcommand{\rdmt}[1]{\edef\rounded{0}\FPeval\rounded{round(#1,\roundpositiont)}\rounded}
\newcommand\BLEU{\textsc{Bleu}\xspace}
\newcommand\TER{\textsc{Ter}\xspace}
\newcommand\WER{\textsc{Wer}\xspace}
\newcommand{\GIZA}{{GIZA\nolinebreak[4]\hspace{-.025em}\raisebox{.2ex}{\small\bf++}}\xspace}
\newcommand{\MGIZA}{{MGIZA\nolinebreak[4]\hspace{-.025em}\raisebox{.2ex}{\small\bf++}}\xspace}
\newcommand{\todo}[1]{ \textcolor{red}{#1} } 

\newenvironment{packed_itemize}{
\begin{itemize}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{itemize}}

\newenvironment{packed_descr}{
\begin{description}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{-1pt}
  \setlength{\parsep}{0pt}
}{\end{description}}


\title{Combined Spoken Language Translation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Please make sure to keep technical paper submissions anonymous  !
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\name{Firstname Lastname}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% If multiple authors, uncomment and edit the lines shown below.       %%
%% Note that each line must be emphasized {\em } by itself.             %%
%% (by Stephen Martucci, author of spconf.sty).                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 \makeatletter
% \def\name#1{\gdef\@name{#1\\}}
% \makeatother
% \name{{\em Firstname1 Lastname1, Firstname2 Lastname2, Firstname3 Lastname3,}\\
%      {\em Firstname4 Lastname4}}
%%%%%%%%%%%%%%% End of required multiple authors changes %%%%%%%%%%%%%%%%%

%\address{Department of Speech Recognition and Machine Translation  \\
%University of SomePlace, SomeCountry \\
%{\small \tt firstname.lastname@iwslt.org}
%}
%
\def\name#1{\gdef\@name{#1\\}}
\makeatother
\name{\bf $\setcounter{footnote}{1} ^\fnsymbol{footnote}$Markus Freitag, $^\fnsymbol{footnote}$Joern Wuebker, $^\fnsymbol{footnote}$Stephan Peitz, $^\fnsymbol{footnote}$Hermann Ney, \\
  \bf $\setcounter{footnote}{3} ^\fnsymbol{footnote}$Matthias Huck, $^\fnsymbol{footnote}$Alexandra Birch, $^\fnsymbol{footnote}$Nadir Durrani, $^\fnsymbol{footnote}$Philipp Koehn, \\
\bf $\setcounter{footnote}{2} ^\fnsymbol{footnote}$Mohammed Mediani, $^\fnsymbol{footnote}$Isabel Slawik, $^\fnsymbol{footnote}$Jan Niehues, $^\fnsymbol{footnote}$Eunah Cho, $^\fnsymbol{footnote}$Alex Waibel, \\
\bf $\setcounter{footnote}{4}^\fnsymbol{footnote}$Nicola Bertoldi, $^\fnsymbol{footnote}$Mauro Cettolo, $^\fnsymbol{footnote}$Marcello Federico \\
  $\setcounter{footnote}{1} ^\fnsymbol{footnote}$RWTH Aachen University, Aachen, Germany\\
  $\setcounter{footnote}{3} ^\fnsymbol{footnote}$University of Edinburgh, Edinburgh, Scotland \\
  $\setcounter{footnote}{2} ^\fnsymbol{footnote}$Karlsruhe Institute of Technology, Karlsruhe, Germany\\
  $\setcounter{footnote}{4} ^\fnsymbol{footnote}$Fondazione Bruno Kessler, Trento, Italy \\
  $\setcounter{footnote}{1} ^\fnsymbol{footnote}${\tt \{freitag,wuebker,peitz,ney\}@cs.rwth-aachen.de} \\
  $\setcounter{footnote}{3} ^\fnsymbol{footnote}${\tt a.birch@ed.ac.uk \{mhuck,dnadir,pkoehn\}@inf.ed.ac.uk} \\
  $\setcounter{footnote}{2} ^\fnsymbol{footnote}${\tt \{firstname.lastname\}@kit.edu} \\
  $\setcounter{footnote}{4} ^\fnsymbol{footnote}${\tt \{bertoldi,cettolo,federico\}@fbk.eu}
}

\address{}

\begin{document}
\maketitle
%
\begin{abstract}
EU-BRIDGE\footnote{\url{http://www.eu-bridge.eu}} is a European research project
which is aimed at developing innovative speech translation technology.
%
One of the collaborative efforts within EU-BRIDGE is to produce
joint submissions of up to four different partners to the evaluation 
campaign at the 2014 International Workshop on Spoken Language
Translation (IWSLT). We submitted combined translations to the German$\to$English
spoken language translation (SLT) track as well as to the German$\to$English,
English$\to$German and English$\to$French machine translation (MT) tracks.
%
In this paper, we present the techniques which were applied by the different 
individual translation systems of RWTH Aachen University, the
University of Edinburgh, Karlsruhe Institute of Technology, and Fondazione
Bruno Kessler. We then show the combination approach developed at RWTH 
Aachen University which combined the individual systems. The consensus
translations yield empirical gains of up to 2.3 points in \BLEU and 1.2 points in \TER
compared to the best individual system.
\end{abstract}


\section{Introduction}
\label{introduction}

The EU-BRIDGE project is funded by the European Union under the Seventh
Framework Programme (FP7) %~\cite{eu:www-fp7} 
and brings together several project
partners who have each previously been very successful in contributing to
advancements in automatic speech recognition and statistical machine
translation. A number of languages and language pairs (both well-covered and
under-resourced ones) are tackled with automatic speech recognition (ASR) and
MT technology with different use cases in mind.  
Four of the EU-BRIDGE project partners are particularly experienced in machine
translation for European language pairs: RWTH Aachen University (RWTH), the
University of Edinburgh (UEDIN), Karlsruhe Institute of Technology (KIT), and
Fondazione Bruno Kessler (FBK) have all regularly participated in large-scale
evaluation campaigns like IWSLT and WMT in recent years, thereby demonstrating
their ability to continuously enhance their systems and promoting progress in
machine translation.
%
Machine translation research within EU-BRIDGE has a strong focus on translation
of spoken language. The IWSLT TED talks task constitutes an interesting
framework for empirical testing of some of the systems for spoken language
translation which are developed as part of the project.

In this work, we describe the EU-BRIDGE submissions to the 2014 IWSLT translation
task. This year, we combined several single systems of RWTH, UEDIN, KIT, and FBK 
for the German$\to$English SLT, German$\to$English MT, English$\to$German MT, and English$\to$French MT tasks.
Additionally to the standard system combination pipeline
presented in \cite{freitag14:jane,matusov:2006:eacl}, we applied a recurrent neural network 
rescoring step \cite{sundermeyer14:bidirRNN} for the English$\to$French MT task.
Similar cooperative approaches based on system combination have proven to be 
valuable for machine translation in previous joint submissions,
e.g.~\cite{freitag14:wmtEuBridge,freitag2013:euBridge}.


The remainder of the paper is structured as follows:
%
We first describe the individual system setups by RWTH Aachen University (Section~\ref{rwth}),
the University of Edinburgh (Section~\ref{uedin}), Karls\-ruhe Institute of Technology
(Section~\ref{kit}), and Fondazione Bruno Kessler (Section~\ref{fbk}),
respectively. We then present the techniques for machine translation system
combination which have been employed to obtain consensus translations from the
outputs of the individual systems of the project partners
(Section~\ref{combination}). Experimental results are given in
Section~\ref{results}. We 
%analyse the translation results in
%Section~\ref{analysis} and 
finally conclude the paper with Section~\ref{conclusion}.


\section{RWTH Aachen University}
\label{rwth}
RWTH applied the identical training pipeline and models on both language pairs:
The state-of-the-art phrase-based baseline systems were augmented with
a hierarchical reordering model, several additional language models (LMs) and 
maximum expected \BLEU training for phrasal, lexical and reordering models.
Further, RWTH employed rescoring with novel recurrent neural language and translation
models. The same systems were used for the SLT track, where RWTH additionally performed
punctuation prediction on the automatic transcriptions employing hierarchical
phrase-based translation.
Both the phrase-based and the hierarchical decoder are implemented in RWTH's publicly available
translation toolkit Jane~\cite{vilar10:jane,wuebker12:jane}.
The model weights of all systems were tuned with standard Minimum Error Rate
Training~\cite{och03:mer} on the provided dev2012 set.
RWTH used \BLEU as optimization objective. For the German$\to$English translation direction, in a preprocessing step the German source was decompounded
\cite{koehn2003:compounds} and part-of-speech-based long-range verb reordering rules
\cite{popovic06:reord} were applied.
RWTH's translation systems are described in more detail in \cite{wuebker14:iwslt}


\subsection{Backoff Language Models}
\label{sec:lms}

Each translation system used three backoff LMs
that were estimated with the KenLM toolkit \cite{Heafield-estimate}:
A large general domain 5-gram LM, an in-domain 5-gram LM and
a 7-gram word class language model (wcLM).
All of them used interpolated Kneser-Ney smoothing.
For the general domain
LM, RWTH first selected $\frac{1}{2}$ of the English Shuffled News,
and $\frac{1}{4}$ of the French Shuffled News as well as both
the English and French Gigaword corpora by the cross-entropy difference
criterion described in \cite{moore:2010:dataselection}. The selection
was then concatenated with all available remaining monolingual data
and used to build and unpruned LM. The in-domain language
models were estimated on the TED data only. For the word class LM,
RWTH trained 200 classes on the target side of the bilingual training
data using an in-house tool similar to \texttt{mkcls}~\cite{mkcls}. 
With these class definitions, RWTH applied the technique shown in 
\cite{wuebker13:wordClassModels} to compute the wcLM on the
same data as the general-domain LM.

\subsection{Maximum Expected \BLEU Training}                                                                                                                                                                       
\label{sec:rprop}

RWTH applied discriminative training, learning three types of features
under a maximum expected \BLEU objective \cite{he12:discr}.
It was performed on the TED portion of the data, which is
high quality in-domain data of reasonable size. This makes training feasible
while at the same time providing an implicit domain adaptation effect.
Similar to \cite{he12:discr}, RWTH generated 100-best lists on the training data
which were used as training samples for a gradient based update method.
Leave-one-out \cite{wuebker2010:PhraseTraining} was applied to
circumvent over-fitting. Here, RWTH followed an approach similar to
\cite{auli14:expBleuReordering}, where each feature type was condensed into a single 
feature for the log-linear model combination. 
In the first pass, RWTH trained phrase pair and phrase-internal
word pair features, and in the second pass a hierarchical reordering model, resulting altogether in an additional eight models
for log-linear combination.


\subsection{Recurrent Neural Network Models}
\label{sec:rnn}

All systems applied rescoring on 1000-best lists using recurrent language and translation models.
The recurrency was handled with the long short-term memory (LSTM) architecture
\cite{hochreiter97:lstm} and RWTH used a class-factored output layer for
increased efficiency as described in \cite{sundermeyer12:lstm}.
All neural networks were trained on the TED portion of the data with 2000 word classes.
In addition to the recurrent language model (RNN-LM), RWTH applied the deep bidirectional word-based translation
model (RNN-BTM) described in \cite{sundermeyer14:bidirRNN}, which is capable of
taking the \emph{full source context} into account for each translation decision.

\subsection{Spoken Language Translation}
\label{sec:slt}

For the SLT task, RWTH reintroduced punctuation and case information before the actual translation similar to \cite{peitz:iwslt2011}.
However, RWTH employed a hierarchical phrase-based system
with a maximum of one nonterminal symbol per rule in place of a phrase-based system.
A punctuation prediction system based on hierarchical translation is able to
capture long-range dependencies between words and punctuation marks and is more
robust for unseen word sequences.
The model weights are tuned with standard MERT on 100-best
lists. As optimization criterion RWTH used $F_{2}$-Score rather than \BLEU or \WER.

Since punctuation predicting and recasing were applied before the actual translation,
the final translation systems from the MT track could be kept completely unchanged.

\section{University of Edinburgh}
\label{uedin}

The UEDIN translation engines are based on the open source Moses
toolkit~\cite{koehn07:moses}. UEDIN set up phrase-based systems
\cite{koehn03:spb} for all SLT and MT tasks covered in this paper, and
additionally a string-to-tree syntax-based system~\cite{Galleyetal:04a} %\cite{Galleyetal:04a,Williams:2012:wmt} 
for the English$\to$German MT task.
%
% The systems were trained using monolingual and parallel data from
% WIT$^3$~\cite{WIT3:2012}, Europarl~\cite{koehn:2005:mtsummit},
% Multi\-UN~\cite{eisele:2010:multiun}, the English and French Gigaword corpora
% as provided by the Linguistic Data Consortium~\cite{ldc:www}, the German
% Political Speeches Corpus~\cite{GerPolCorpus}, and the Common Crawl, $10^9$, and
% News Commentary corpora from the WMT shared task training
% data~\cite{wmt:www-14-task}.
%
The systems were trained using monolingual and parallel data from
WIT$^3$, Europarl,
Multi\-UN, the English and French Gigaword corpora
as provided by the Linguistic Data Consortium, the German
Political Speeches Corpus, and the Common Crawl, $10^9$, and
News Commentary corpora from the WMT shared task training
data.
%
Word alignments for the MT track systems were created by aligning the data in both
directions with \MGIZA~\cite{Gao:2008:MGIZA} and symmetrizing the two trained
alignments~\cite{och03:alignmentComparison,koehn03:spb}. 
Word alignments for the SLT track system were created using
fast\_align~\cite{dyer13:fast_align}.
%
The SRILM toolkit~\cite{stolcke02:srilm} was employed to train 5-gram LMs
with modified Kneser-Ney smoothing~\cite{chen98:aes}. UEDIN trained
individual LMs on each corpus and then interpolated them
using weights tuned to minimize perplexity on a development set. 

Common features included in the UEDIN phrase-based systems are:
\vspace*{-1ex}
\begin{packed_itemize}
\item The language model
\item Phrase translation scores in both directions, smoothed with Good-Turing discounting
\item Lexical translation scores in both directions
\item Word and phrase penalties
\item Six simple count-based binary features
\item Distance-based distortion cost
\item A hierarchical lexicalized reordering model~\cite{galley-manning:2008:EMNLP} 
\item Sparse lexical and domain indicator features~\cite{iwslt12:Hasler-2}
\item Operation sequence models over different word representations~~\cite{durrani-EtAl:2014:Coling} %~\cite{birch-etal:2013:IWSLT,durrani-EtAl:2014:Coling} 
\end{packed_itemize}
\vspace*{-1ex}
%
Model weights for the log-linear model combination %\cite{och02:meForSMT} 
were optimized with batch MIRA~\cite{cherry:2012:bts} to maximize
\BLEU~\cite{papineni02:bam}.

\subsection{Spoken Language Translation}
\label{uedin:slt}

%UEDIN trained a phrase-based German$\to$English SLT system for this system combination paper.

One of the main challenges of spoken language translation is to overcome the
mismatch in the style of data that the speech recognition systems output, and the
written text that is used to train the translation model. ASR system output lacks punctuation and
capitalization, which is 
the main stylistic differences. Previous research~\cite{Matusov:2006:IWSLT,peitz:iwslt2011,ref:cho}
suggests that it is preferrable to punctuate the text before translation, which is
what UEDIN did by training a translation system on the German side of the parallel data.
The ``source language'' of the system had punctuation
and capitalization stripped, and the ``target language'' was the standard German parallel text.
%UEDIN used 4.6 million sentences of parallel
%data from Europarl, WIT, New Commentary, and the UN corpora for both this punctuation model and the subsequent translation model.
The handling of punctuation is similar to the other groups in this paper, however UEDIN used a phrase-based
model with no distortion or reordering, and tuned the model to the ASR input text using
batch MIRA and the \BLEU score.

% Our translation system applied an operation sequence model (OSM) over the basic phrase-based decoding
% model~\cite{durrani-EtAl:2013:Short,durrani-EtAl:2013:NAACL}. OSM  addresses the problem of the
% phrasal independence assumption since the model considers context beyond phrasal boundaries.
% The OSM model represents a bilingual sentence
% pair and its alignment through a sequence of operations that generate the aligned sentence pair. An
% operation either generates source and target words
% or it performs reordering by inserting gaps and
% jumping forward and backward. It has shown to improve performance over many language pairs, and
% to help even more when sequence models are applied over more general factors such as POS tags and
% Brown clusters~\cite{birch-etal:2013:IWSLT}. For this experiment we applied OSM models over words,
% lemmas, POS tags, and a source morphology tag to target POS tag model.

\subsection{Machine Translation}


\subsubsection{German$\to$English MT}

For the UEDIN German$\to$English MT task system,
pre-reordering~\cite{collins-koehn-kucerova:2005:ACL} and compound
splitting~\cite{ref:koehn2003a} were applied to the German source language side
in a preprocessing step.  A factored translation model~\cite{koehn2012factor}
was employed. Source side factors are word, lemma, part-of-speech (POS) tag, and
morphological tag. Target side factors are word, lemma, and POS tag.
%
%In addition to the features listed above, 
UEDIN incorporated two additional LMs into the German$\to$English MT system:
a 7-gram LM over POS tags (trained on WIT$^3$ only) and
a 7-gram LM over lemmas (trained on WIT$^3$ only).
%
Model weights were optimized on a concatenation of dev2010 and dev2012.


\subsubsection{English$\to$French MT}

UEDIN contributed two phrase-based systems for the English$\to$French EU-BRIDGE
system combination. Both comprise Brown clusters with 200 classes as additional
factors on source and target side.  The system denoted as UEDIN-A  was trained
without the Multi\-UN and $10^9$ corpora, the system denoted as UEDIN-B was
trained with all corpora.
%
An additional feature incorporated into the systems is an LM over Brown
clusters (UEDIN-A: 7-gram, UEDIN-B: 5-gram).
%
Model weights were optimized on dev2010.

\subsubsection{English$\to$German MT}

UEDIN contributed two phrase-based systems (UEDIN-A and UEDIN-B) and a
syntax-based system (UEDIN-C) for English$\to$German MT.

\textit{Phrase-based systems.} UEDIN-A and UEDIN-B employ factored models.
Source side factors are word, POS tag, and Brown cluster (2000 classes). Target
side factors are word, POS tag, Brown cluster (2000 classes), and morphological
tag. UEDIN-A was trained with all corpora, whereas for UEDIN-B the parallel
training data was restricted to the in-domain WIT$^3$ corpus. 
%
Additional features of the systems are: a 5-gram LM over Brown clusters, a
7-gram LM over morphological tags (UEDIN-A: trained on all data, UEDIN-B:
trained on WIT$^3$ only), and a 7-gram LM over POS tags (UEDIN-A, not UEDIN-B).
%
Model weights of UEDIN-B were optimized on dev2010, model weights of UEDIN-A on
a concatenation of dev2010 and dev2012.

\textit{Syntax-based system.} UEDIN-C is a string-to-tree translation system
with similar features as the ones described
in~\cite{williams-uedinsyntaxwmt14}. The target-side data was parsed with
BitPar \cite{schmid2004bitpar}, and right binarization was applied to the parse
trees. The system was adapted to the TED domain by extracting separate rule
tables (from the WIT$^3$ corpus and from the rest of the parallel data) and
merging them with a fill-up technique~\cite{iwslt11:Bisazza}. Augmenting the
system with non-syntactic phrases~\cite{huck-hoang-koehn:2014:W14-33} and
adding soft source syntactic constraints~\cite{huck-hoang-koehn:2014:SSST-8}
yielded further improvements.
%
Model weights of UEDIN-C were optimized on a concatenation of dev2010 and
dev2012.


\section{Karlsruhe Institute of Technology}
\label{kit}

The KIT translations were generated by an in-house phrase-based translations
system~\cite{ref:vogel-decoder}. The models were trained on the Europarl, News
Commentary, WIT$^3$, Common Crawl corpora for all directions, as well as on the
additional monolingual training data. The noisy Crawl corpora were filtered
using an SVM classifier~\cite{ref:mediani2011}.  In addition to the standard
preprocessing, KIT used compound splitting~\cite{ref:koehn2003a} for the German
text when translating from German.  In the SLT task, KIT first recased the
input and added punctuation marks to the ASR hypotheses. This was done with a
monolingual translation system as shown in~\cite{ref:cho}.
 
In all translation directions, KIT used a pre-reordering approach. Different
reorderings of the source sentences were encoded in a word lattice. For the
English$\to$French system, only short-range rules were used to generate these
lattices~\cite{ref:rottmann2007}.  Long-range rules~\cite{ref:niehues2009} and
tree-based reordering rules~\cite{ref:herrmann2013syntax} were used for
German$\to$English. The POS tags needed for these rules were generated  by the
TreeTagger~\cite{ref:schmid1994} and the parse trees by the Stanford
Parser~\cite{ref:stanfordParser}.  In addition, for the language pairs
involving German KIT applied the different reorderings of both language pairs
using a lexicalized reordering model. %~\cite{ref:koehn2005}. 
% TODO: It's not clear to me what this means: "applied the different
% reorderings of both language pairs ..."; do you just want to say that you
% used lexicalized reordering for the German tasks (but not for
% English$\rightarrow$French)?

The phrase tables of the systems were trained using \GIZA
alignment~\cite{och03:alignmentComparison}. KIT adapted the phrase table to the
TED domain using the backoff approach and by means of candidate
selection~\cite{Niehues2012PhraseTableAdaptation}.  In addition to the phrase
table probabilities, KIT modeled the translation process by a bilingual language
model~\cite{niehues2011} and a discriminative word lexicon using source
context features~\cite{niehues-waibel:2013:wmt}. 

During decoding, KIT used several LMs to adapt the system to the task and to
better model the sentence structure using a class-based LM.  For the
German$\to$English task, KIT used one LM trained on all data, an in-domain LM
trained only on the WIT$^3$ corpus, and one LM trained on 5M sentences selected
using cross-entropy difference~\cite{moore:2010:dataselection}. As classes KIT
used the clusters obtained using the \texttt{mkcls} algorithm on the
WIT$^3$ corpus. For German$\leftrightarrow$ English, KIT used a 9-gram LM
with 100 or 1000 clusters and for the English$\to$French MT task,  a
cluster-based 4-gram LM was trained on 500 clusters. For English$\to$German, KIT
also used a 9-gram POS-based LM.

The log-linear combination of all these models was optimized on the provided
development data using MERT. % \cite{ref:venugopal2005}. 

\section{Fondazione Bruno Kessler}
\label{fbk}
\input fbk

\section{System Combination}
\label{combination}
\label{sec:syscom}

\begin{figure*}[t!]
\resizebox{\linewidth}{!}{
    \includegraphics{pictures/syscombi-architecture.pdf}
}
\vspace*{-1.5em}
\caption{Confusion network decoding structure.}
\vspace*{-1.0em}
\label{fig:syscomStructure}
\end{figure*}

In this section, we give a brief re-introduction of confusion network system combination.
System combination is used to produce consensus translations from multiple
hypotheses which are outputs of different translation engines. The consensus
translations can be better in terms of translation quality than any of the
individual hypotheses. 
To combine the engines of the project partners for the EU-BRIDGE joint setups,
we applied a system combination implementation that has been developed at RWTH
Aachen University ~\cite{freitag14:jane}.

In Figure \ref{fig:syscomStructure} an overview is illustrated.
We first address the generation of a confusion network (CN) from $I$ input translations. 
For that we need a pairwise alignment between all input hypotheses. This alignment
is calculated via METEOR~\cite{banerjee05:maa}. The
hypotheses are then reordered to match the word order of a selected
skeleton hypothesis. Instead of using only one of the input hypothesis as skeleton, we
generate $I$ different CNs each having one of the input systems as skeleton. The final
lattice is the union of all $I$ previous generated CNs.
In Figure~\ref{fig:1}
an example confusion network of $I=4$ input translations with one skeleton translation is illustrated. Between two adjacent nodes, we always
have a choice between the $I$ different system output words.
The confusion network decoding step basically involves determining the shortest path through 
the network. Each arc is assigned one score which is a linear model combination (Equation~\ref{eq:loglin})
of $M$ different models.

\begin{equation}
\label{eq:loglin}
 \sum_{m=1}^M \lambda_m h_m
\end{equation}

The standard set of models is a word penalty, a 3-gram language
model trained on the input hypotheses, and for each system one binary voting feature.
During decoding the binary voting feature for system $i$ ($1 \leq i \leq I$) is~1 iff the word is from system $i$, otherwise~0.
The $M$ different model weights $\lambda_m$ are trained with MERT~\cite{och03:mer}.

\begin{figure}[ht]
\centering
\includegraphics[width=0.85\linewidth]{pictures/example1}
\vspace*{-0.5em}
\caption{System A: \emph{the red cab} ; System B: \emph{the red train} ; System C: \emph{a blue car} ; System D: \emph{a green car} ; Reference: \emph{the blue car} .}
\label{fig:1}
\vspace*{-1.2em}
\end{figure}

%
\section{Results}
\label{results}

In this section, we present our experimental results. All reported \BLEU~\cite{papineni02:bam} and \TER~\cite{snover06:aso}
scores are case-sensitive with one reference. All system combination results have been generated with
RWTH's open source system combination implementation Jane~\cite{freitag14:jane}.

\subsection{German$\to$English SLT}
For the German$\to$English SLT task, we combined three different individual systems
generated by UEDIN, KIT, and RWTH. Experimental results are given in Table~\ref{tab:DeEnSLTResults}.
The final system combination yields improvements of 1.5 points in \BLEU and 
1.2 points in \TER compared to the best single system (KIT). All single systems as
well as the system combination parameters were tuned on dev2012. For this year's IWSLT SLT track,
dev2012 was the only given test set containing automatic speech recognition output.

\begin{table}[bt!]
\caption{Results for the German$\to$English SLT task.}
%Bold font indicates system combination results that are significantly better than the best single system (p $<$ 0.05).}
  %\vspace*{1.4em}
  \begin{center}
    \begin{tabular}{l|c|c}
      %\hline
      \bf{system} & \multicolumn{2}{c}{\bf{dev2012}} \\
                  & \small{\BLEU} & \TER \\
       \hline \hline
       \textbf{KIT}                               & \rdm{20.7182832044} & \rdm{60.50384083210076} \\
       \textbf{RWTH}                              & \rdm{20.7958068268} & \rdm{61.41991507228398} \\
       \textbf{UEDIN}                             & \rdm{20.289498398} & \rdm{62.95624791259125} \\ \hline
       \textbf{syscom}                            & \rdm{22.2321791584} & \rdm{59.27763729185552} \\
      \end{tabular}
     \end{center}
     \label{tab:DeEnSLTResults}
   \end{table}


\subsection{German$\to$English MT}

Similar to the SLT track, the German$\to$English MT system combination submission is a combined translation of three different individual systems
by UEDIN, KIT, and RWTH. Experimental results are given in Table~\ref{tab:DeEnResults}. The system combination parameters have been optimized on test2012. 
Compared to the best individual system (RWTH), the system combination improved translation scores by up to 1.5 points in \BLEU and
1.1 points in \TER.

\begin{table}[bt!]
\caption{Results for the German$\to$English MT task.}
%Bold font indicates system combination results that are significantly better than the best single system (p $<$ 0.05).}
  %\vspace*{1.4em}
  \begin{center}
    \begin{tabular}{l|c|c|c|c|c|c}
      %\hline
      \bf{system} & \multicolumn{2}{c|}{\bf{tst2010}} & \multicolumn{2}{c|}{\bf{tst2011}}  & \multicolumn{2}{c}{\bf{tst2012}} \\
                  & \small{\BLEU} & \TER & \small{\BLEU} & \TER & \small{\BLEU} & \TER \\
       \hline \hline
       \textbf{KIT}                                & \rdm{31.5055077292} & \rdm{47.606222869997783} & \rdm{37.0506652671} & \rdm{42.45201517484882} & \rdm{31.9539484287} & \rdm{47.58388819302525} \\
       \textbf{RWTH}                               & \rdm{31.8236101862} & \rdm{47.162637432274007} & \rdm{38.3003021787} & \rdm{41.321413815122265} & \rdm{31.9973577528} & \rdm{47.00046146746654}  \\
%       \textbf{UEDIN}                              & \rdm{31.3718719338} & \rdm{47.69810842495485} & \rdm{37.2750140709} & \rdm{42.57596814784209} & \rdm{31.6082745411} & \rdm{47.91680400817457} \\ \hline
       \textbf{UEDIN}                              & \rdm{31.61} & \rdm{47.61} & \rdm{37.30} & \rdm{42.54} & \rdm{31.68} & \rdm{47.90} \\ \hline
       \textbf{syscom}                             & \rdm{33.3225473047} & \rdm{46.07585310985077} & \rdm{39.4434507166} & \rdm{40.60774518273673} & \rdm{33.4725712172} & \rdm{46.16322763530885} \\
 %      \textbf{}                              & \rdm{} & \rdm{} & \rdm{} & \rdm{} & \rdm{} & \rdm{} &\\
      \end{tabular}
     \end{center}
     \label{tab:DeEnResults}
   \end{table}

\subsection{English$\to$French MT}

For the English$\to$French MT task, we combined five different individual systems. FBK, KIT, and RWTH provided one individual system output
for the system combination. UEDIN added one advanced contrastive system in addition to their primary system. Experimental results are given in Table~\ref{tab:EnFrResults}. 
The system combination of all five individual systems yields an improvement of up to 0.6 points in \BLEU compared to the best RWTH individual system output.
Using a recurrent neural network (RNN) LM to rescore a 1000-best list of the system combination output, leads to a small translation
improvement of +0.1 in \BLEU. The same RNN LM was applied in the best individual system of RWTH Aachen. The improvements are only small,
as the model is already contained the best individual system.

\begin{table}[bt!]
\caption{Results for the English$\to$French MT task.}
%Bold font indicates system combination results that are significantly better than the best single system (p $<$ 0.05).}
  %\vspace*{1.4em}
  \begin{center}
    \resizebox{0.98\textwidth}{!}{\begin{minipage}{\textwidth}
    \begin{tabular}{l|c|c|c|c|c|c}
      %\hline
      \bf{system} & \multicolumn{2}{c|}{\bf{tst2010}} & \multicolumn{2}{c|}{\bf{tst2011}}  & \multicolumn{2}{c}{\bf{tst2012}} \\
                  & \small{\BLEU} & \TER & \small{\BLEU} & \TER & \small{\BLEU} & \TER \\
       \hline \hline
       \textbf{FBK}                               & \rdm{32.7992} & \rdm{50.4449} & \rdm{39.1848} & \rdm{42.6122} & \rdm{40.0121} & \rdm{41.3801} \\
       \textbf{KIT}                               & \rdm{33.1161} & \rdm{48.3904} & \rdm{37.2869} & \rdm{42.4766} & \rdm{39.1408} & \rdm{40.2053} \\
       \textbf{RWTH}                              & \rdm{34.5252} & \rdm{47.5973} & \rdm{41.1475} & \rdm{40.1044} & \rdm{41.9988} & \rdm{38.5893} \\
%       \textbf{UEDIN-A}                           & \rdm{33.5323} & \rdm{48.5871} & \rdm{40.226} & \rdm{40.6602} & \rdm{40.6096} & \rdm{39.7641} \\
       \textbf{UEDIN-A}                           & \rdm{33.62} & \rdm{48.51} & \rdm{40.23} & \rdm{40.61} & \rdm{40.99} & \rdm{39.58} \\
%       \textbf{UEDIN-B}                           & \rdm{33.1165} & \rdm{49.2085} & \rdm{39.0833} & \rdm{42.0293} & \rdm{40.2152} & \rdm{39.9577} \\ \hline
       \textbf{UEDIN-B}                           & \rdm{33.23} & \rdm{49.12} & \rdm{39.13} & \rdm{41.95} & \rdm{40.67} & \rdm{39.76} \\ \hline
       \textbf{syscom}                            & \rdm{35.1119} & \rdm{48.5091} & \rdm{41.6735} & \rdm{41.3786} & \rdm{43.9523} & \rdm{38.6568} \\
       \textbf{ +RNN}                            & \rdm{35.2208} & \rdm{48.5278} & \rdm{41.7089} & \rdm{41.2702} & \rdm{44.3163} & \rdm{38.5443}
      \end{tabular}
    \end{minipage}}
     \end{center}
     \label{tab:EnFrResults}
   \end{table}

\subsection{English$\to$German MT}

For the English$\to$German setup, we combined three different individual system setups of UEDIN with the primary submission of KIT. Experimental results
are given in Table~\ref{tab:EnDeResults}. All system combination parameters are tuned on tst2012. The EU-BRIDGE submission enhanced the translation quality by
up to 1.4 points in \BLEU and 1.2 points in \TER compared to the best individual system.

\begin{table}[bt!]
\caption{Results for the English$\to$German MT task.}
%Bold font indicates system combination results that are significantly better than the best single system (p $<$ 0.05).}
  %\vspace*{1.4em}
  \begin{center}
    \resizebox{0.98\textwidth}{!}{\begin{minipage}{\textwidth}
    \begin{tabular}{l|c|c|c|c|c|c}
      %\hline
      \bf{system} & \multicolumn{2}{c|}{\bf{tst2010}} & \multicolumn{2}{c|}{\bf{tst2011}}  & \multicolumn{2}{c}{\bf{tst2012}} \\
                  & \small{\BLEU} & \TER & \small{\BLEU} & \TER & \small{\BLEU} & \TER \\
       \hline \hline
       \textbf{KIT}                              &        \rdm{24.5282} & \rdm{55.1522} & \rdm{27.0848} & \rdm{50.5152} & \rdm{23.5199} & \rdm{56.0189} \\
%       \textbf{UEDIN-A}                              &\rdm{24.5109} & \rdm{55.6562} & \rdm{27.6276} & \rdm{50.1502} & \rdm{23.2898} & \rdm{56.9536} \\
       \textbf{UEDIN-A}                              &\rdm{24.85} & \rdm{55.47} & \rdm{27.82} & \rdm{50.05} & \rdm{23.37} & \rdm{56.90} \\
%       \textbf{UEDIN-B}                              &\rdm{23.7506} & \rdm{55.8934} & \rdm{26.5083} & \rdm{50.9411} & \rdm{22.0828} & \rdm{57.3336} \\
       \textbf{UEDIN-B}                              &\rdm{24.12} & \rdm{55.73} & \rdm{26.73} & \rdm{50.84} & \rdm{22.19} & \rdm{57.26} \\
%       \textbf{UEDIN-C}                              &\rdm{24.3881} & \rdm{55.4684} & \rdm{26.2983} & \rdm{50.6293} & \rdm{23.008} & \rdm{56.6899} \\ \hline
       \textbf{UEDIN-C}                              &\rdm{24.75} & \rdm{55.31} & \rdm{26.45} & \rdm{50.54} & \rdm{23.11} & \rdm{56.62} \\ \hline
       \textbf{syscom}                              &\rdm{25.8934} & \rdm{54.0387} & \rdm{28.1208} & \rdm{49.0931} & \rdm{24.9475} & \rdm{55.0294} \\
      \end{tabular}
      \end{minipage}}
     \end{center}
     \label{tab:EnDeResults}
   \end{table}




%\section{Error Analysis}
%\label{analysis}

\section{Conclusion}
\label{conclusion}

We achieved better translation performance
with gains of up to +2.3 points in \BLEU
and -1.2 points in \TER by combining the different
system hypotheses of up to four partners of the EU-BRIDGE project.
The four research institutes (RWTH Aachen University,
University of Edinburgh, Karlsruhe Institute
of Technology, Fondazione Bruno Kessler) are maintaining
different machine translation engines based on different
approaches. System combination combined all the different
advancements of all engines together into our final
submissions. For English$\to$French we applied a
recurrent neural network language model in an additional
rescoring step which only gives small improvement of +0.1 points in \BLEU.


\section{Acknowledgements}

The research leading to these results has received funding from the European
Union Seventh Framework Programme (FP7/2007-2013) under grant agreement
n\textsuperscript{o}~287658. % EU-BRIDGE


\bibliographystyle{IEEEtran}
\bibliography{translation}

\end{document}

