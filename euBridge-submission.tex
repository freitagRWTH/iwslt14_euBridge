\documentclass[a4paper]{article}
\usepackage{iwslt14,amssymb,amsmath,epsfig,url}
\setcounter{page}{1}
\sloppy		% better line breaks
%\ninept
%SM below a registered trademark definition
\def\reg{{\rm\ooalign{\hfil
     \raise.07ex\hbox{\scriptsize R}\hfil\crcr\mathhexbox20D}}}

\usepackage{mathptmx}
\usepackage{fp}
\usepackage{xspace}
\usepackage{color}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{booktabs}

\def\roundposition{1}
\def\roundpositiont{3}
\edef\rounded{0}
\newcommand{\rdm}[1]{\edef\rounded{0}\FPeval\rounded{round(#1,\roundposition)}\rounded}
\newcommand{\rdmt}[1]{\edef\rounded{0}\FPeval\rounded{round(#1,\roundpositiont)}\rounded}
\newcommand\BLEU{\textsc{Bleu}\xspace}
\newcommand\TER{\textsc{Ter}\xspace}
\newcommand{\GIZA}{{GIZA\nolinebreak[4]\hspace{-.025em}\raisebox{.2ex}{\small\bf++}}\xspace}
\newcommand{\todo}[1]{ \textcolor{red}{#1} } 


\title{EU-BRIDGE MT: Text Translation of Talks in the EU-BRIDGE Project}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Please make sure to keep technical paper submissions anonymous  !
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\name{Firstname Lastname}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% If multiple authors, uncomment and edit the lines shown below.       %%
%% Note that each line must be emphasized {\em } by itself.             %%
%% (by Stephen Martucci, author of spconf.sty).                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 \makeatletter
% \def\name#1{\gdef\@name{#1\\}}
% \makeatother
% \name{{\em Firstname1 Lastname1, Firstname2 Lastname2, Firstname3 Lastname3,}\\
%      {\em Firstname4 Lastname4}}
%%%%%%%%%%%%%%% End of required multiple authors changes %%%%%%%%%%%%%%%%%

%\address{Department of Speech Recognition and Machine Translation  \\
%University of SomePlace, SomeCountry \\
%{\small \tt firstname.lastname@iwslt.org}
%}
%
\def\name#1{\gdef\@name{#1\\}}
\makeatother
\name{\bf $\setcounter{footnote}{1} ^\fnsymbol{footnote}$Markus Freitag, $^\fnsymbol{footnote}$JoernWuebker, $^\fnsymbol{footnote}$Stephan Peitz, $^\fnsymbol{footnote}$Hermann Ney, \\
    \bf $\setcounter{footnote}{3} ^\fnsymbol{footnote}$Mathias Huck, $^\fnsymbol{footnote}$Philipp Koehn, \\
\bf $\setcounter{footnote}{2} ^\fnsymbol{footnote}$Mohammed Mediani,$\setcounter{footnote}{2} ^\fnsymbol{footnote}$Isabel Slawik,$\setcounter{footnote}{2} ^\fnsymbol{footnote}$Jan Niehues,$\setcounter{footnote}{2} ^\fnsymbol{footnote}$Eunah Cho, $\setcounter{footnote}{2} ^\fnsymbol{footnote}$Alex Waibel, \\
\bf $\setcounter{footnote}{4} ^\fnsymbol{footnote}$Nicola Bertoldi, $^\fnsymbol{footnote}$Mauro Cettolo, $ ^\fnsymbol{footnote}$Marcello Federico \\
  $\setcounter{footnote}{1} ^\fnsymbol{footnote}$RWTH Aachen University, Aachen, Germany\\
  $\setcounter{footnote}{3} ^\fnsymbol{footnote}$University of Edinburgh, Edinburgh, Scotland \\
  $\setcounter{footnote}{2} ^\fnsymbol{footnote}$Karlsruhe Institute of Technology, Karlsruhe, Germany\\
  $\setcounter{footnote}{4} ^\fnsymbol{footnote}$Fondazione Bruno Kessler, Trento, Italy \\
  $\setcounter{footnote}{1} ^\fnsymbol{footnote}${\tt \{freitag,wuebker,peitz,ney\}@cs.rwth-aachen.de} \\
  $\setcounter{footnote}{3} ^\fnsymbol{footnote}${\tt \{mhuck,pkoehn\}@inf.ed.ac.uk} \\
  $\setcounter{footnote}{2} ^\fnsymbol{footnote}${\tt \{firstname.lastname\}@kit.edu} \\
  $\setcounter{footnote}{4} ^\fnsymbol{footnote}${\tt \{bertoldi,cettolo,federico\}@fbk.eu}
}

\address{}

\begin{document}
\maketitle
%
\begin{abstract}
EU-BRIDGE\footnote{\url{http://www.eu-bridge.eu}} is a European research project
which is aimed at developing innovative speech translation technology.
%
This paper describes one of the collaborative efforts within EU-BRIDGE to
further advance the state of the art in machine translation between two European
language pairs, English$\to$French and German$\to$English. Four research institutions
involved in the EU-BRIDGE project combined their individual machine translation
systems and participated with a joint setup in the machine translation track of
the evaluation campaign at the 2014 International Workshop on Spoken Language
Translation (IWSLT).

We present the methods and techniques to achieve high translation quality for
text translation of talks which are applied at RWTH Aachen University, the
University of Edinburgh, Karlsruhe Institute of Technology, and Fondazione
Bruno Kessler. We then show how we have been able to considerably boost
translation performance (as measured in terms of the metrics \BLEU and \TER) by
means of system combination. The joint setups yield empirical gains of up to
1.4 points in \BLEU and 2.8 points in \TER on the WMT newstest sets compared to
the best single systems.
\end{abstract}


\section{Introduction}
\label{introduction}

The International Workshop on Spoken Language Translation \cite{iwslt:www-13} hosts a yearly open
evaluation campaign on the translation of TED talks \cite{tedTalks:www}.
The TED talks task is challenging from the perspective of automatic speech
recognition (ASR) and machine translation (MT) as it involves spontaneous
speech and heterogeneous topics and styles. The task is open domain, with
a wide range of heavily dissimilar subjects and jargons across talks.
IWSLT subdivides the task and separately evaluates \emph{automatic
transcription of talks from audio to text}, \emph{speech translation of
talks from audio}, and \emph{text translation of talks} as three different tracks 
\cite{federico11:iwslt,IWSLT:2012}. The training data is constrained to the
corpora specified by the organizers. The supplied list of corpora comprises a
large amount of publicly available monolingual and parallel training data,
though, including WIT$^3$~\cite{WIT3:2012},
Europarl~\cite{koehn:2005:mtsummit}, Multi\-UN~\cite{eisele:2010:multiun}, the
English and French Gigaword corpora as provided by the Linguistic Data
Consortium~\cite{ldc:www}, and the News Crawl, $10^9$ and News Commentary
corpora from the WMT shared task training data~\cite{wmt:www-13-task}. For the
two ``official'' language pairs~\cite{iwslt:www-13} for translation at
IWSLT 2013, English$\to$French and German$\to$English, these resources allow for
building of systems with state-of-the-art performance by participants.

The EU-BRIDGE project is funded by the European Union under the Seventh
Framework Programme (FP7)~\cite{eu:www-fp7} and brings together several project
partners who have each previously been very successful in contributing to
advancements in automatic speech recognition and statistical machine
translation. A number of languages and language pairs (both well-covered and
under-resourced ones) are tackled with ASR and MT technology with different use
cases in mind.  
Four of the EU-BRIDGE project partners are particularly experienced in machine
translation for European language pairs: RWTH Aachen University (RWTH), the
University of Edinburgh (UEDIN), Karlsruhe Institute of Technology (KIT), and
Fondazione Bruno Kessler (FBK) have all regularly participated in large-scale
evaluation campaigns like IWSLT and WMT in recent years, thereby demonstrating
their ability to continuously enhance their systems and promoting progress in
machine translation.
%
Machine translation research within EU-BRIDGE has a strong focus on translation
of spoken language. The IWSLT TED talks task constitutes an interesting
framework for empirical testing of some of the systems for spoken language
translation which are developed as part of the project.

The work described here is an attempt to attain translation quality beyond
strong single system performance via system
combination~\cite{matusov:2006:eacl}.  Similar cooperative approaches based on
system combination have proven to be valuable for machine translation in other
projects, e.g.\ in the Quaero
programme~\cite{freitag12:quaeroJointSub,peitz13:quaero}.
Within EU-BRIDGE, we built combined system setups for text translation of talks
from English to French as well as from German to English. We found that the
combined translation engines of RWTH, UEDIN, KIT, and FBK systems are very
effective. In the rest of the paper we will give some insight into the
technology behind the combined engines which have been used to produce the
joint EU-BRIDGE submission to the IWSLT 2013 MT track.

The remainder of the paper is structured as follows:
%
We first describe the individual English$\to$French and German$\to$English
systems by RWTH Aachen University (Section~\ref{rwth}), the University of
Edinburgh (Section~\ref{uedin}), Karls\-ruhe Institute of Technology
(Section~\ref{kit}), and Fondazione Bruno Kessler (Section~\ref{fbk}),
respectively. We then present the techniques for machine translation system
combination which have been employed to obtain consensus translations from the
outputs of the individual systems of the project partners
(Section~\ref{combination}).  Experimental results in
\BLEU~\cite{papineni02:bam} and \TER~\cite{snover06:aso} are given in
Section~\ref{results}. A brief error analysis on selected examples from the
test data has been conducted which we discuss in
Section~\ref{analysis}. We finally conclude the paper with
Section~\ref{conclusion}.


\section{RWTH Aachen University}
\label{rwth}


\section{University of Edinburgh}
\label{uedin}


\section{Karlsruhe Institute of Technology}
\label{kit}
The KIT translations are generated by an in-house phrase-based translations system \cite{ref:vogel-decoder}. The models are trained on the EPPS, NC, TED, Common Crawl corpora for all directions and the additional monolingual training data. The noisy Crawl corpora were filtered using an SVM classifier \cite{ref:mediani2011}.
In addition to the standard preprocessing, we used compound splitting \cite{ref:koehn2003a} for the German text when translating from German.
In the SLT task, we first recased the input and added punctuation marks to the ASR hypotheses. Therefore, we used a monolingual translation system as shown in \cite{ref:cho} .
 
In all translation directions, we used a pre-reordering approach. We encode different reorderings of the source sentences in a word lattice. For the English$\rightarrow$French system, we only usd short-range rules \cite{ref:rottmann2007} to generate these lattices.  For German$\rightarrow$English, we also used long-range rules \cite{ref:niehues2009} and tree-based reordering rules \cite{ref:herrmann2013syntax}. The part-of-speech (POS) tags needed for these rules were generated  by the TreeTagger \cite{ref:schmid1994} and the parse trees by the Stanford Parser \cite{ref:stanfordParser}.
In addition, for the language pairs involving German we score the different reorderings of both language pairs using a lexicalized reordering model\cite{ref:koehn2005}.

The phrase tables of the systems are trained using Giza++ alignment \cite{och03:asc}. We adapt the phrase table to the TED domain using the backoff approach and by also adapting the candidate selection \cite{Niehues2012PhraseTableAdaptation}.  In addition to the phrase table probabilities, we model the translation process by a bilingual language model \cite{niehues2011} and a discriminative word lexicon(DWL) using source context features \cite{niehues-waibel:2013:wmt}. 

During decoding, we use several language models to adapt the system to the task and to better model the sentence structure using class-based language model. For the German$\rightarrow$English task, we use one language model trained on all data, an in-domain language model trained only on the TED corpus and one language model trained on 5M sentences selected using cross-entropy difference \cite{moore:2010:dataselection}. Finally, we also used a cluster language model, trained on the TED corpus using the MKCLS \cite{mkcls} algorithm to cluster the words. For $German\leftrightarrow$ English, we used a 9-gram model with 100 or 1000 clusters and for English$\rightarrow$French translation task,  a cluster-based 4-gram language model was trained on 500 clusters. For English$\rightarrow$German, we also used an 9-gram POS-based language model. For the E. 

We optimize the log-linear combination of all these models on the provided development data using MERT\cite{ref:venugopal2005}. 

\section{Fondazione Bruno Kessler}
\label{fbk}


\section{System Combination}
\label{combination}
System combination is used to produce consensus translations from multiple
hypotheses which are outputs of different translation engines. The consensus
translations can be better in terms of translation quality than any of the
individual hypotheses. 
To combine the engines of the project partners for the EU-BRIDGE joint setups,
we applied a system combination implementation that has been developed at RWTH
Aachen University.\pagebreak

The basic concept of RWTH's approach to machine translation system combination
has been described by Freitag et al.~\cite{freitag14:jane}.
This approach includes an enhanced alignment and reordering framework.
Alignments between the system outputs are learned using METEOR~\cite{banerjee05:maa}.
A confusion network is then built using one of the hypotheses as ``primary''
hypothesis. We do not make a hard decision on which of the hypotheses to use 
for that, but instead combine all possible confusion networks into a single lattice.  
Majority voting on the generated lattice is performed using the prior 
probabilities for each system as well as other statistical models, e.g.\ 
a special $n$-gram language model which is learned on the input hypotheses.
Scaling factors of the models are optimized using the Minimum Error Rate
Training algorithm. The translation with the best total score within the
lattice is selected as consensus translation.


\section{Results}
\label{results}

In this section, we present our experimental results. All scores are given in
truecase \BLEU~\cite{papineni02:bam} and truecase \TER~\cite{snover06:aso}.



\subsection{German$\to$English MT track}


\begin{table}[bt!]
  \caption{Results for the German$\to$English translation task. Bold font indicates system combination results that are significantly better than the best single system (p $<$ 0.05).}
  %\vspace*{1.4em}
  \begin{center}
    \begin{tabular}{l|c|c|c|c|c|c}
      %\hline
      \bf{system} & \multicolumn{2}{c|}{\bf{tst2010}} & \multicolumn{2}{c|}{\bf{tst2011}}  & \multicolumn{2}{c}{\bf{tst2012}} \\
      & \BLEU & \TER & \BLEU & \TER & \BLEU & \TER \\
       \hline \hline
       \textbf{UEDIN}                              & \rdm{31.3718719338} & \rdm{47.69810842495485} & \rdm{37.2750140709} & \rdm{42.57596814784209} & \rdm{31.6082745411} & \rdm{47.91680400817457} \\ 
       \textbf{KIT}                              & \rdm{31.5055077292} & \rdm{47.606222869997783} & \rdm{37.0506652671} & \rdm{42.45201517484882} & \rdm{31.9539484287} & \rdm{47.58388819302525} \\
       \textbf{RWTH}                        & \rdm{31.8236101862} & \rdm{47.162637432274007} & \rdm{38.3003021787} & \rdm{41.321413815122265} & \rdm{31.9973577528} & \rdm{47.00046146746654}  \\  \hline   
    \textbf{syscom}                              & \rdm{33.3225473047} & \rdm{46.07585310985077} & \rdm{39.4434507166} & \rdm{40.60774518273673} & \rdm{33.4725712172} & \rdm{46.16322763530885} \\
 %      \textbf{}                              & \rdm{} & \rdm{} & \rdm{} & \rdm{} & \rdm{} & \rdm{} &\\
      \end{tabular}
     \end{center}
     \label{tab:DeEnResults}
   \end{table}

\subsection{English$\to$French}

\begin{table}[bt!]
  \caption{Results for the English$\to$French translation task. Bold font indicates system combination results that are significantly better than the best single system (p $<$ 0.05).}
  %\vspace*{1.4em}
  \begin{center}
    \begin{tabular}{l|c|c|c|c|c|c}
      %\hline
      \bf{system} & \multicolumn{2}{c|}{\bf{tst2010}} & \multicolumn{2}{c|}{\bf{tst2011}}  & \multicolumn{2}{c}{\bf{tst2012}} \\
      & \BLEU & \TER & \BLEU & \TER & \BLEU & \TER \\
       \hline \hline
        \textbf{FBK}                              & \rdm{32.7992} & \rdm{50.4449} & \rdm{39.1848} & \rdm{42.6122} & \rdm{40.0121} & \rdm{41.3801} \\
        \textbf{KIT}                              & \rdm{33.1161} & \rdm{48.3904} & \rdm{37.2869} & \rdm{42.4766} & \rdm{39.1408} & \rdm{40.2053} \\
       \textbf{RWTH}                              & \rdm{34.5252} & \rdm{47.5973} & \rdm{41.1475} & \rdm{40.1044} & \rdm{41.9988} & \rdm{38.5893} \\
       \textbf{UEDIN-B}                           & \rdm{33.1165} & \rdm{49.2085} & \rdm{39.0833} & \rdm{42.0293} & \rdm{40.2152} & \rdm{39.9577} \\
       \textbf{UEDIN-A}                           & \rdm{33.5323} & \rdm{48.5871} & \rdm{40.226} & \rdm{40.6602} & \rdm{40.6096} & \rdm{39.7641} \\ \hline
       \textbf{syscom}                            & \rdm{35.1119} & \rdm{48.5091} & \rdm{41.6735} & \rdm{41.3786} & \rdm{43.9523} & \rdm{38.6568} \\
      \end{tabular}
     \end{center}
     \label{tab:EnFrResults}
   \end{table}

\subsection{English$\to$German}

\begin{table}[bt!]
  \caption{Results for the English$\to$German translation task. Bold font indicates system combination results that are significantly better than the best single system (p $<$ 0.05).}
  %\vspace*{1.4em}
  \begin{center}
    \begin{tabular}{l|c|c|c|c|c|c}
      %\hline
      \bf{system} & \multicolumn{2}{c|}{\bf{tst2010}} & \multicolumn{2}{c|}{\bf{tst2011}}  & \multicolumn{2}{c}{\bf{tst2012}} \\
      & \BLEU & \TER & \BLEU & \TER & \BLEU & \TER \\
       \hline \hline
       \textbf{KIT}                              &        \rdm{24.5282} & \rdm{55.1522} & \rdm{27.0848} & \rdm{50.5152} & \rdm{23.5199} & \rdm{56.0189} \\
       \textbf{UEDIN-B}                              &\rdm{23.7506} & \rdm{55.8934} & \rdm{26.5083} & \rdm{50.9411} & \rdm{22.0828} & \rdm{57.3336} \\
       \textbf{UEDIN-C}                              &\rdm{24.3881} & \rdm{55.4684} & \rdm{26.2983} & \rdm{50.6293} & \rdm{23.008} & \rdm{56.6899} \\
       \textbf{UEDIN-A}                              &\rdm{24.5109} & \rdm{55.6562} & \rdm{27.6276} & \rdm{50.1502} & \rdm{23.2898} & \rdm{56.9536} \\ \hline
       \textbf{syscom}                              &\rdm{25.8934} & \rdm{54.0387} & \rdm{28.1208} & \rdm{49.0931} & \rdm{24.9475} & \rdm{55.0294} \\
      \end{tabular}
     \end{center}
     \label{tab:EnDeResults}
   \end{table}


\subsection{German$\to$English SLT track}


\begin{table}[bt!]
  \caption{Results for the German$\to$English SLT translation task. Bold font indicates system combination results that are significantly better than the best single system (p $<$ 0.05).}
  %\vspace*{1.4em}
  \begin{center}
    \begin{tabular}{l|c|c}
      %\hline
      \bf{system} & \multicolumn{2}{c}{\bf{dev2012}} \\
      & \BLEU & \TER \\
       \hline \hline
       \textbf{UEDIN}                              & \rdm{20.289498398} & \rdm{62.95624791259125} \\
        \textbf{KIT}                              & \rdm{20.7182832044} & \rdm{60.50384083210076} \\
       \textbf{RWTH}                              & \rdm{20.7958068268} & \rdm{61.41991507228398} \\ \hline
       \textbf{syscom}                              & \rdm{22.2321791584} & \rdm{59.27763729185552} \\
      \end{tabular}
     \end{center}
     \label{tab:DeEnSLTResults}
   \end{table}


\section{Error Analysis}
\label{analysis}

\section{Conclusion}
\label{conclusion}


\bibliographystyle{IEEEtran}
\bibliography{translation}

\end{document}

